---
title: k8s网络篇一-Linux底层技术
date: 2024-08-21T18:35:54+08:00
lastmod: 2024-08-21T18:35:54+08:00
author: wantflying
authorlink: https://github.com/wantflying
cover: img/cat.jpg
categories:
  - k8s
tags:
  - 网络
  - Linux
draft: false
---

k8s 向我们提供各种网络插件、网络资源，例如 Flannel、Calico、Cilium、Weave 各种网络插件。在使用之前我们需要理解它们是如何工作的，这样才能在遇到问题时能有清晰的认识，能够知其所以然。本文将依次介绍 Linux 为我们提供的工具：namespace、veth pair、iptables、Linux bridge、tun/tap 设备、iptables、ipip、vxlan、macvlan、ipvlan，以及当前最新的 ebpf 技术，这个后续开单独模块介绍。

<!--more-->

# namespace

- **作用：** 为进程提供一个隔离的环境，从进程角度来看，整个服务器就它一个进程存在，完全独占系统资源，Linux 在各个内核版本升级过程中给我们提供了不同的 namespace 隔离，包括存储挂载、系统信号量、网络、主机名、进程、cgroup
- **原理：** Linux 使用 clone()函数创建 namespace，会在/proc/pid/ns 目录下生成符号链接，链接到对应文件，只要文件一直存在，namespace 就不会消失。通过 setns()方法可以将进程放入指定 namespace，unshare()可以将指定进程从 namespace 移出。例如我们如果要进入某个 namesapce 下，也是要先拿到 namespace 对应的文件描述符，然后通过 setns 添加进程，然后就可以执行自己的程序。至于这些函数底层原理是什么，感兴趣自行了解。

# veth pair

- **作用：** veth 就是一个虚拟以太网卡，pair 就是一对的意思，那么一对虚拟网卡就是说我们往其中一个 veth 发送数据，就会转发到另外一个 veth，要注意 veth pair 的作用仅仅是将数据从一个网卡发送到另外一个网卡，前面我们也提到 namesapce 网络空间隔离，那我们就可以把 veth 放在根命令空间和新的网络空间，实现有限制的网络访问。
- **案例：** 接下来我们将创建一对 veth pair，并测试他们之间的网络访问情况
  ![](https://raw.githubusercontent.com/wantflying/blog/main/static/img/vethpair-1.png)如上图所示，当前服务器只有一个默认的 ens160 网卡，我们可以通过 _ip link add vethname1 type veth peer name vethname2_，创建一对 veth pair，当前这一对 veth 都是在根 namespace 下，且网卡状态都是 down，也就是当前没啥用，只是单纯创建出来。
  ![](https://raw.githubusercontent.com/wantflying/blog/main/static/img/vethpair-2.png)
  接下来将两个 veth 启动并设置两个不同的网段，veth1 的 IP 地址是 10.0.2.100，veth0 的地址是 10.0.1.100。
  ![](https://raw.githubusercontent.com/wantflying/blog/main/static/img/vethpair-3.png)
  此时我们在根 namespace ping veth1 和 veth0 都可以 ping 通，路由表也可以看到分别创建了两条路由规则，这个时候其实跟 pair 没啥关系，单纯可以理解就是分别创建了两个不同的虚拟网卡，只有他们在不同的网络 namespace 才能感受到 pair 的意义。接着我们通过 ip netns 创建两个不同的命令空间，这个是 linux 为我们封装好的一个工具去操作网络 namespace，其他 namespace 的操作都需要编写相应的 c 代码。接着再把 veth0 放入 netns0 空间，veth1 放到 netns1 空间，此时我们再去 ping 这两个网址，已经无法 ping 通，因为他们分别处在不同的网络 namespace。此时如果进入 netns0 或者 netns1，可以看到网卡已经被重置变成 down 状态，路由表信息也是全为空的。
  ![](https://raw.githubusercontent.com/wantflying/blog/main/static/img/vethpair-4.png)
  如上图所示，我们再次把 veth0 和 veth1 启动起来，然后在 netns0 的空间下去 ping veth1，发现 ping 不通，那么问题来了不是说两个是个 pair 吗？可以互相通的？但是这是我们逻辑上的理解，那还是要强调一下 pair 的作用：**将一端网卡的数据传送到另外一端**。是不是可以看出问题所在，我们需要先将数据送到我们的网卡上，那这个原因是本地路由没有 10.0.2.0/24，所以我们的数据压根送不到我们自己的 veth0 网卡上，所以我们只要给我们的 namespace 添加一条路由即可。但是这也只是解决了报文去的问题，回的问题也需要在 netns1 上创建相应的路由。至此跨 namespace 的网络访问就可以通了，对于各自 namespace 的网络设备都是独立的，其实如果 vth0 和 veth1 如果是在同一网段，那么也就可以直接使用默认的路由规则进行访问，无须手工添加路由规则。

# Linux Bridge

- **作用：** 对于两个不同的 namespace 可以通过 veth pair 进行访问，但是当存在多个 namespace 隔离的时候，就需要一个东西来实现不同 namespace 之间进行访问，这个就是 Linux Bridge,也可以理解为她是一个二层的物理交换机，bridge 上面有不同端口，可根据 mac 地址转发到相应端口。
- **案例：** 创建一个 bridge，并绑定 veth pair，进行网络测试，总结一下就是说只要一个虚拟网卡链接上去，那它就不会再和网络协议栈通信，而是把流量交给网桥，至于网桥能不能和网络协议栈通信，那就不管了。k8s中也有应用，就是pod中放置一个veth pair中一个，另外一个veth挂载根namespace 空间的网桥上，外面的veth没有ip地址，pod内部流量通过veth pair转发到根namespace veth上，然后再转给bridge，由bridge根网络协议栈通信。至此单节点pod之间内部通信其实就可以使用这种方式完成。

```shell
#当前环境虚拟机ip是192.168.123.111，网关是192.168.123.1

## 创建一个名称为br0的网桥，并启动  也可以通过 brctl addbr br0创建
[root@node1 ~]# ip link add name br0 type bridge
[root@node1 ~]# ip link set br0 up

## 创建一个veth0和veth1的pair，启动并设置ip地址
[root@node1 ~]# ip link add veth0 type veth peer name veth1
[root@node1 ~]# ip addr add 1.2.3.101/24 dev veth0
[root@node1 ~]# ip addr add 1.2.3.102/24 dev veth1
[root@node1 ~]# ip link set veth0 up
[root@node1 ~]# ip link set veth1 up

## 将veth0绑定到br0网桥上 或者使用 brctl addif br0 veth0
[root@node1 ~]# ip link set dev veth0 master br0

## 查看bridge绑定情况
[root@node1 ~]# bridge link
7: veth0 state UP @veth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master br0 state forwarding priority 32 cost 2

## 此时我们理解的网络拓扑图应该是这样，但是后面通过实验可以发现有些地方存在问题

网络协议栈<------> br0 <------> veth0 <------> veth1
|                                ’|’          ’|’
|---------------------------------|------------|

## 此时从veth0 ping veth1地址，会发现无法ping通，在网卡veth1抓包发现接受到报文，但是无返回
## 同样操作从veth1 ping veth0，也是同样现象
## 同时我们发现veth0的mac地址和br0 mac地址相同
##🙅‍♂️这里还是存在一些问题，可能跟我的本地环境有关系，我是用的虚拟机，也许跟内核版本有关系，反正资料说是这里会返回reply报文给veth0，然后veth0会返回给br0，但是br0并没有将数据给网络栈，因此无法获得veth1的mac地址，从而导致二层网络不通，无法不通，折腾很久，后续有机会再验证？？？？
[root@node1 ~]# ping -c 1 -I veth0 1.2.3.102
PING 1.2.3.102 (1.2.3.102) from 1.2.3.101 veth0: 56(84) bytes of data.

--- 1.2.3.102 ping statistics ---
1 packets transmitted, 0 received, 100% packet loss, time 0ms
[root@node1 ~]# tcpdump -n -i veth1
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes
19:03:10.496023 ARP, Request who-has 1.2.3.102 tell 1.2.3.101, length 28
19:03:11.574961 ARP, Request who-has 1.2.3.102 tell 1.2.3.101, length 28
19:03:12.608699 ARP, Request who-has 1.2.3.102 tell 1.2.3.101, length 28

```
